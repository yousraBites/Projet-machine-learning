---
title: "Projet machine learning"
author: "Yousra AMACHAT, Tomilli RAKOTOZAFY et Thiziri BENABDELAZIZ" 
date: "2025-02-25"
output:
  pdf_document:
    latex_engine: xelatex
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loan Approval Classification Dataset

## **1. Description Générale**

1.  Le contexte de notre jeu de données :

    Ce jeu de données porte sur des demandes de prêts soumises à un
    établissement financier. Chaque observation représente un individu
    ayant sollicité un prêt, avec un ensemble de variables caractérisant
    :

    -   Les informations personnelles (âge, revenu, genre, statut
        d’occupation du logement…)

    -   L’expérience professionnelle

    -   Le montant du prêt et son objectif,

    -   L’historique de crédit (score, défauts précédents, etc.).

    L’idée est donc de répertorier toutes ces informations afin de mieux
    comprendre les profils des demandeurs et de prévoir la probabilité
    d’acceptation ou de rejet du prêt.

2.  Notre objectif :

    L’objectif principal est de construire un modèle de classification
    permettant de déterminer si un nouveau demandeur aura son prêt
    approuvé (“loan_status”) ou non, en fonction des caractéristiques et
    du comportement crédit de l’individu (âge, revenus, historique de
    crédit, etc.).

## **2. Jeu de données :**

1.  Charger le jeu de données :

    Le jeu de données est sous format **csv.**

    Nous avons relevé des individus dont l’âge dépassait 100 ans, voire
    123 ans, ce qui nous a semblé irréaliste dans le cadre de cette
    étude (notamment pour expliquer 101 ans d’expérience
    professionnelle). De tels enregistrements s’apparentent fortement à
    des erreurs de saisie et risquent de biaiser notre analyse. Nous
    avons donc choisi de supprimer ces observations pour maintenir la
    cohérence et la fiabilité de notre jeu de données. Puis on a décidé
    de réduire notre data set a 5000 observation au lieu de 45 000 pour
    faciliter la tache, en générant un échantillon aléatoire.

    ```{r}
    #charger notre jeu de donnnees :
    data=read.csv("C:\\Users\\yousr\\Desktop\\projet ml\\loan_data.csv") 
    #la dimension initiale 
    dim(data)

    #suppression des lignes dont age > 100 : 
    nrow(data[data$person_age > 100, ])  
    which(data$person_age > 100) 
    idx = which(data$person_age > 100)  
    data = data[-idx, ]  
    nrow(data[data$person_age > 100, ]) #pour êtres sur que les ligne sont supprimees.

    #reduction de notre jeu de donnees : 
    #permet de generer le meme echantillon a chaaue fois :
    set.seed(123)

    #Générer un vecteur d'indices aléatoires de taille 5000 et Extraire l'échantillon de 5000 lignes :
    data = data[sample(seq_len(nrow(data)), size = 5000), ]

    # Pour vérifier la dimension du nouveau data frame :
    dim(data)
    ```

2.  Caractéristiques de jeu de données :

    ```{r}
    nrow(data)  
    ncol(data)  
    #dim(data)
    ```

    Il y a 5000 individus et 14 variables dans ce jeu de données.

3.  Variables :

    ```{r}
    colnames(data)  
    #str(data)
    head(data)  
    sapply(data, class)
    ```

    une description courte de chacune des variables et leur types :

    -   Variables quantitatives (numériques) :

        -   person_age : Âge de la personne, emprunteur.

        -   person_income : Revenu annuel de la personne.

        -   person_emp_exp : Expérience professionnelle en années.

        -   loan_amnt : Montant du prêt demandé.

        -   loan_int_rate : Taux d’intérêt du prêt.

        -   loan_percent_income : Pourcentage du revenu utilisé pour
            rembourser le prêt.

        -   cb_person_cred_hist_length : Longueur de l’historique de
            crédit de la personne (en années).

        -   credit_score : Score de crédit de la personne (l’échelle
            FICO).

    -   Variables qualitatives (catégorielles) :

        -   person_gender : Genre de la personne.

        -   person_education : Niveau d’éducation atteint.

        -   person_home_ownership : Statut de propriété du logement.

        -   loan_intent : Objet ou but du prêt.

        -   previous_loan_defaults_on_file : Indique si la personne a
            déjà fait défaut sur un prêt.

        -   loan_status : Statut final du prêt.

4.  Target :

    ```{r}
    target = factor(data$loan_status, labels=c("rejeté", "approuvé") ) 
    class(target)
    ```

    La variable qui sera le target est loan_status que l'on transforme
    en factor.

5.  Variables peu pertinentes :

    Avant de poursuivre notre analyse, **nous** avons jugé nécessaire
    d’identifier **d’autres** variables pouvant être considérées comme
    moins pertinentes, que ce soit en raison de risques de biais ou de
    discrimination, ou encore de redondances liées à d’autres variables
    plus informatives. Voici les principales concernées :

    -   person_gender : pour éviter d’introduire un risque de
        discrimination

    -   person_education : peut introduire des biais (pour des questions
        éthiques)

    -   person_income et loan_amnt : elles sont corrélées avec
        loan_percent_income, qui est un ratio dérivé de ces deux
        variables 

6.  Transformation des variables :

    Avons nous besoin de normaliser ou min-max ....etc ??

    1.  La discrétisation de credit_score selon l’échelle FICO :

        **l’échelle FICO :**

        -   300 à 579 : Crédit “faible” (poor) – considéré comme très
            risqué par la plupart des prêteurs.

        -   580 à 669 : Crédit “moyen/limite” (fair) – encore considéré
            comme « subprime » ou “à risque” selon certains critères.

        -   670 à 739 : Crédit “bon” (good).

        -   740 à 799 : Crédit “très bon” (very good).

        -   800 à 850 : Crédit “excellent” (exceptionnel).

    ```{r}
    data$credit_score = cut(
        data$credit_score,
        breaks = c(300, 580, 670, 740, 800, 851),  # 851 permet d'inclure 850 dans le dernier intervalle
        labels = c("faible", "moyen", "bon", "très bon", "excellent"),
        include.lowest = TRUE,
        right = FALSE  # intervalles fermés à gauche et ouverts à droite : [300,580), [580,670), etc.
    )
    data$credit_score
    ```

    2.  La transformation de pevious_loan_defaults_on_file en binaire
        (yes = 1 et no=0)

    ```{r}
    data$previous_loan_defaults_on_file=1*(data$previous_loan_defaults_on_file == "Yes")
    ```

    Apres les modification precedentes on a :

    -   Variables quantitatives (numériques) :

        -   person_age

        -   person_emp_exp

        -   loan_int_rate

        -   loan_percent_income

        -   cb_person_cred_hist_length

    -   Variables qualitatives (catégorielles) :

        -   person_home_ownership

        -   loan_intent

        -   previous_loan_defaults_on_file

        -   credit_score

    3.  La transformation des variables catégorielles en factor :

    ```{r}
    #transformation de credit_score en factor
    data$credit_score = as.factor(data$credit_score)
    class(data$credit_score)

    #transformation de data$person_home_ownership en factor
    data$person_home_ownership = as.factor(data$person_home_ownership)
    class(data$person_home_ownership)

    #transformation de data$loan_intent en factor
    data$loan_intent = as.factor(data$loan_intent)
    class(data$loan_intent)

    #transformation de credit_score en factor
    data$previous_loan_defaults_on_file = as.factor(data$previous_loan_defaults_on_file)
    class(data$previous_loan_defaults_on_file)
    ```

7.  Variables prédictives :

    ```{r}
    #contenant les variables qualitatives que l'on souhaite utiliser pour la prédiction
    qualitative_vars = data.frame(cred_score=data$credit_score, home_own= data$person_home_ownership, intent=data$loan_intent, prev_def=data$previous_loan_defaults_on_file)

    ##contenant les variables quantitatives que l'on souhaite utiliser pour la prédiction
    quantitative_vars = data.frame(age=data$person_age, emp_exp = data$person_emp_exp, perc_inc=data$loan_percent_income, int_rate = data$loan_int_rate , cred_hist=data$cb_person_cred_hist_length)
    ```

8.  Variables aberrantres :

    ```{r}
    # Supposons que 'quantitative_vars' soit un data frame avec vos variables numériques

    for (v in colnames(quantitative_vars)) {
      # Récupérer la colonne sous forme de vecteur
      x <- quantitative_vars[[v]]
      
      # Calcul des stats du boxplot
      stats_v <- boxplot.stats(x)$out  # outliers selon Tukey
      
      if (length(stats_v) > 0) {
        cat("Variable:", v, "\n")
        cat("Nombre d'outliers:", length(stats_v), "\n")
        cat("Valeurs d'outliers:", stats_v, "\n\n")
      }
    }
    ```

## **3. Analyse descriptive (univariee):**

1.  Analyse statistique descriptive :

    a\. variables quantitatives :

    l'analyse statistique descriptive de chacune des variables
    quantitatives incluses dans quantitative_vars

    ```{r}
    summary(quantitative_vars)
    ```

    On constate tout d’abord que la médiane d’âge (26 ans) est
    relativement basse, laissant penser que la moitié de l’échantillon a
    moins de 26 ans, ce qui suggère un public plutôt jeune. Par
    ailleurs, certaines valeurs 0  pour l’expérience professionnelle
    (person_emp_exp) peuvent correspondre à de jeunes actifs ou,
    éventuellement, à des données manquantes recodées, il serait donc
    pertinent de vérifier ce point. De même, un ratio de prêt
    (loan_percent_income) à 0 % soulève la question d’un revenu très
    élevé ou d’un montant de prêt symbolique, il serait utile d’examiner
    si ces cas sont bien réels ou s’il s’agit d’anomalies. Enfin, la
    présence d’un taux d’intérêt pouvant aller jusqu’à 30 % laisse
    entrevoir des prêts de type subprime  ou à risque plus élevé, ce qui
    peut influer sur les décisions de crédit et mérite une analyse plus
    approfondie.

    b\. variables qualitatives :

    l'analyse statistique descriptive de chacune des variables
    quantitatives incluses dans qualitative_vars

    ```{r}
    summary(qualitative_vars)
    ```

    On remarque que, pour la variable *credit_score*, la catégorie
     excellent  est inexistante, alors même qu’une majorité des dossiers
    se situent dans les classes intermédiaires (faible, moyen/limite,
    bon). Cette absence de scores  excellent  peut surprendre, mais elle
    peut aussi refléter la composition de l’échantillon, davantage
    centré sur des profils risqués ou moyens. Par ailleurs, la variable
    *previous_loan_defaults_on_file* montre un équilibre presque parfait
    entre  yes  (2473) et no  (2527), ce qui signifierait qu’environ la
    moitié des individus ont déjà fait défaut. Un tel taux de défaut
    peut paraître élevé, mais il se peut que le jeu de données soit
    spécifiquement orienté vers des clients à risque, ce qui
    expliquerait cette répartition.

    c\. Target :

    Le nombre d’observations tombées dans les des deux catégories de la
    réponse (`target`)

    ```{r}
    summary(target)
    ```

    Sur l’ensemble des demandes, 3 904 ont été rejetées et 1 096
    approuvées. Cela traduit une répartition nettement inégale, avec
    davantage de rejets que d’approbations dans le jeu de données.

    Puisque le nombre de crédits rejetés est largement plus grand que le
    nombre de crédits acceptes cela peut amener a une accuracy
    trompeuse. Donc il faut utiliser une métrique adaptee pour évaluer
    les classifieurs.

    Sinon on peut reequilibreer le jeu d'entrainement evec
    surechantillonnage ou sous-echantillopnnage ou bien smote.

2.  Analyse graphiques :

    a\. variables quantitatives :

    Pour les variables quantitatives on peut utiliser : l'histogramme,
    scatterplot et boxplot

    ```{r ,out.width="50%", fig.align = "center"}
    # l'histogramme
    hist(quantitative_vars$person_age, col="pink", main ="Histogramme d'Age")
    hist(quantitative_vars$person_emp_exp , col="pink", main ="Histogramme du nombre d'annee d'experience")
    hist(quantitative_vars$loan_int_rate, col="pink", main ="Histogramme du taux d'interet du credit")
    hist(quantitative_vars$loan_percent_income, col="pink", main ="Histogramme du pourcentage du credit dans le revenu")
    hist(quantitative_vars$cb_person_cred_hist_length, col="pink", main ="Histogramme du historiaue de la longueur du credit de la personne")

    #ou bien pour l'histogramme
    for(i in 1:ncol(quantitative_vars)){
      main_i = paste0("Boxplot de ", colnames(quantitative_vars)[i])
      boxplot(quantitative_vars[,i], col = i+1, main = main_i,
              xlab = colnames(quantitative_vars)[i])
    }

    # boxplot
    boxplot(quantitative_vars$person_age, col="5", main ="Boxplot d'Age")
    boxplot(quantitative_vars$person_emp_exp, col="5", main ="Boxplot du nombre d'annee d'experience")
    boxplot(quantitative_vars$loan_percent_income, col="5", main ="Boxplot du pourcentage du credit dans le revenu")
    boxplot(quantitative_vars$loan_int_rate, col="5", main ="Boxplot du pourcentage du taux d'interet du credit")
    boxplot(quantitative_vars$cb_person_cred_hist_length, col="5", main ="Boxplot du historiaue de la longueur du credit de la personne")


    #ou bien pour boxplot
    for(i in 1:ncol(quantitative_vars)){
      main_i = paste0("Histogramme de ", colnames(quantitative_vars)[i])
      hist(quantitative_vars[,i], col = i+1, main = main_i,
              xlab = colnames(quantitative_vars)[i])
    }
    ```

    b\. variables qualitatives :

    ```{r}
    # Barplot 
    for(i in 1:ncol(qualitative_vars)){
      main_i = paste0("Barplot de ", colnames(qualitative_vars)[i])
      barplot(summary(qualitative_vars[,i]), col = 2:10, main = main_i,
              xlab = colnames(qualitative_vars)[i])
    }
    ```

## **4. Analyse descriptive (multivariee):**

1.  Variables quantitatives :

    On utilise heatmap

    ```{r}
    #install.packages("ggplot2")

    # 1) Charger les packages
    library(reshape2)  # pour la fonction melt()
    library(ggplot2)   # pour ggplot()

    # 2) Supposons que vos variables quantitatives soient dans 'quantitative_vars'
    #    (par ex. person_age, person_emp_exp, loan_int_rate, loan_percent_income, cb_person_cred_hist_length)
    #    Calcul de la matrice de corrélation
    cor_mat <- cor(quantitative_vars, use = "complete.obs")

    # 3) Transformation en format "long" pour ggplot
    melted_cor_mat <- melt(cor_mat)

    # 4) Visualisation
    ggplot(data = melted_cor_mat, aes(x = Var1, y = Var2, fill = value)) +
      geom_tile() +
      scale_fill_gradient2(low = "blue", mid = "white", high = "red") +
      scale_x_discrete(labels = c(
        "person_age"                 = "Age", 
        "person_emp_exp"             = "Annees d'exp",
        "loan_int_rate"              = "Taux d’intérêt",
        "loan_percent_income"        = "% Revenu",
        "cb_person_cred_hist_length" = "Hist du Crédit"
      )) +
      scale_y_discrete(labels = c(
        "person_age"                 = "Age", 
        "person_emp_exp"             = "Annees d'exp",
        "loan_int_rate"              = "Taux d’intérêt",
        "loan_percent_income"        = "% Revenu",
        "cb_person_cred_hist_length" = "Hist du Crédit"
      )) +
      labs(title = "Correlation Heatmap", x = "", y = "", fill = "Corrélation") +
      theme(
        axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text.y = element_text(angle = 45, hjust = 1)
      )
    ```

2.  Variables quantitatives et target :

    ```{r}
    for(i in 1:ncol(quantitative_vars)){
      main_i = paste0("Boxplot de ", colnames(quantitative_vars)[i], 
                      "\n en fonction de l'acceptation du credit ")
      
      ylab_i = paste0(colnames(quantitative_vars)[i])
      
      boxplot(quantitative_vars[,i] ~ target, col = c("pink", "lightblue"),
              main = main_i, ylab = ylab_i, xlab = "Acceptation du credit")
    }
    ```

    La moyenne des variables quantitatives dans chacune des catégories
    de la target

    ```{r}
    for(i in 1:ncol(quantitative_vars)){
      print(paste0("La moyenne pour la variable ", colnames(quantitative_vars)[i], 
                   " parmi les credit aui sont approuves est de ", 
                   round(mean(quantitative_vars[which(target == "approuvé"), i], 
                              na.rm = TRUE), digits = 2)))
      
      print(paste0("La moyenne pour la variable ", colnames(quantitative_vars)[i], 
                   " parmi les credit aui sont rejetes est de ", 
                   round(mean(quantitative_vars[which(target == "rejeté"), i], 
                              na.rm = TRUE), digits = 2)))
    }
    ```

3.  variables qualitatives et target :

    ```{r}
    library(ggplot2)

    for (i in 1:ncol(qualitative_vars)) {
      var1 <- as.character(qualitative_vars[, i])
      var1[is.na(var1)] <- "NA"      # Remplacer les NA par la chaîne "NA"
      var1 <- as.factor(var1)
      
      # Initialiser un data frame vide avec les colonnes souhaitées
      counts <- data.frame(
        var1 = character(),
        target = character(),
        personnes_num = numeric(),
        stringsAsFactors = FALSE
      )
      
      # Boucle pour remplir `counts`
      for (j in levels(var1)) {
        for (k in levels(target)) {
          tmp <- data.frame(
            var1 = j,
            target = k,
            personnes_num = sum(target == k & var1 == j),
            stringsAsFactors = FALSE
          )
          counts <- rbind(counts, tmp)
        }
      }
      
      # Convertir en factor ou numeric si besoin
      counts$var1 <- factor(counts$var1)
      counts$target <- factor(counts$target)
      counts$personnes_num <- as.numeric(counts$personnes_num)
      
      # Plot
      xlab_i <- paste0(colnames(qualitative_vars)[i])
      p <- ggplot(data = counts, aes(x = var1, y = personnes_num, fill = target)) +
        geom_bar(stat = "identity", color = "black") +
        theme_minimal() +
        labs(
          x = xlab_i,
          fill = "Credit approuve",
          y = "Nombre de personnes"
        )
      
      print(p)
    }

    ```

autres

```{r}
for (i in 1:ncol(qualitative_vars)) {
  var1 <- as.character(qualitative_vars[, i])
  var1[is.na(var1)] <- "NA"      # Remplacer les NA par la chaîne "NA"
  var1 <- as.factor(var1)
  
  # Initialiser un data frame vide avec les colonnes souhaitées
  counts <- data.frame(
    var1 = character(),
    target = character(),
    personnes_num = numeric(),
    stringsAsFactors = FALSE
  )
  
  # Boucle pour remplir `counts` : on compte, pour chaque niveau de var1 et chaque niveau de target
  for (j in levels(var1)) {
    for (k in levels(target)) {
      tmp <- data.frame(
        var1 = j,
        target = k,
        personnes_num = sum(target == k & var1 == j),
        stringsAsFactors = FALSE
      )
      counts <- rbind(counts, tmp)
    }
  }
  
  # Convertir en factor ou numeric si besoin
  counts$var1 <- factor(counts$var1)
  counts$target <- factor(counts$target)
  counts$personnes_num <- as.numeric(counts$personnes_num)
  
  # Préparation du label de l'axe des x
  xlab_i <- paste0(colnames(qualitative_vars)[i])
  
  # Plot
  print(
    ggplot(data = counts, aes(x = var1, y = personnes_num, fill = target)) +
      geom_bar(stat = "identity", color = "black", position = "fill") +
      theme_minimal() +
      labs(
        x = xlab_i,
        fill = "Acceptation du credit", 
        y = "Proportion de personnes"
      ) +
      theme(
        axis.text.x = element_text(angle = 45, hjust = 1)
      )
  )
}
```

## **5. Données manquantes :**

1.  Identifier les variables avec des données manquantes :

    Notre data set ne contient pas de données manquantes.

    ```{r}
    colSums(is.na(data))  
    # ou bien 
    for (i in 1:ncol(quantitative_vars)){
      print(paste0("il manque l avaleur de la variable  ", colnames(quantitative_vars)[i],"  chez  ", sum(is.na(quantitative_vars[,i])), " personnes"))
    }

    print (" ------------------------------------------------------------------------")
    quantitative_vars <- data[, c(
      "person_age",
      "person_emp_exp",
      "loan_percent_income",
      "loan_int_rate",
      "cb_person_cred_hist_length"
    ), drop = FALSE]  # Extraire en tant que data frame

    for (i in 1:ncol(qualitative_vars)){
      print(paste0("il manque l avaleur de la variable  ", colnames(qualitative_vars)[i],"  chez  ", sum(is.na(qualitative_vars[,i])), " personnes"))
    }
    ```

## 6. Ensembles d'apprentissage et de test :

1.  Holdout method

    ```{r}
    # Chargement du package caret
    library(caret)
    set.seed(123)

    # Partition du jeu de données complet en train (80%), test (10%) et validation (10%)
    trainIndex <- createDataPartition(target, p = 0.8, list = FALSE)
    trainData  <- data[trainIndex, ]
    tempData   <- data[-trainIndex, ]

    testIndex <- createDataPartition(target[-trainIndex], p = 0.5, list = FALSE)
    testData  <- tempData[testIndex, ]
    valData   <- tempData[-testIndex, ]

    # Ensuite, si vous souhaitez ne retenir que certaines variables pour la prédiction,
    # par exemple celles que vous avez définies en variables prédictives,
    # vous pouvez créer un data frame avec ces variables :
    predictive_vars <- cbind(
      quantitative_vars,  # variables quantitatives sélectionnées
      qualitative_vars    # variables qualitatives sélectionnées
    )

    # Vous pouvez alors extraire ces variables pour chaque ensemble :
    train_predictors <- predictive_vars[trainIndex, ]
    test_predictors  <- predictive_vars[-trainIndex, ][testIndex, ]
    val_predictors   <- predictive_vars[-trainIndex, ][setdiff(seq_len(nrow(tempData)), testIndex), ]

    # Extraction de la cible
    y_train <- target[trainIndex]
    y_test  <- target[-trainIndex][testIndex]
    y_val   <- target[-trainIndex][setdiff(seq_len(nrow(tempData)), testIndex)]


    # Vérification des dimensions
    cat("Dimension du jeu d'entraînement :", dim(train_predictors), "\n")
    cat("Dimension du jeu de test :", dim(test_predictors), "\n")
    cat("Dimension du jeu de validation :", dim(val_predictors), "\n")

    y_train
    y_test
    y_val
    head(y_train)
    ```

2.  k-fold cross validation

    caret effectue déjà la recherche du meilleur `k`
    \*\*automatiquement. Nous n’avons pas à relancer manuellement le
    modèle pour tester d’autres valeurs de `k.`

    Cela indique à caret de tester 10 valeurs différentes pour
    l’hyperparamètre `k` (par défaut, ce sont généralement des entiers
    autour de sqrt(n)

    caret va, pour chaque valeur de `k`, effectuer la cross-validation.
    Il calcule la métrique (ROC, Accuracy, etc.) moyenne sur les 10
    plis. Il retient la valeur de `k` qui donne la meilleure
    performance.

    ```{r}
    library(MLmetrics)
    library(Metrics)
    library(caret)

    # Configuration de la validation croisée en 10 folds
    #train_control <- trainControl(
    #  method = "cv",                # Utilisation de la cross-validation
    #  number = 10,                  # 10 folds
    #  classProbs = TRUE,            # Pour calculer les probabilités de classe
    #  summaryFunction = twoClassSummary,  # Pour calculer l'AUC et autres métriques adaptées à la classification binaire
    #  savePredictions = "final"     # (Optionnel) pour sauvegarder les prédictions finales sur chaque fold
    #)

    train_control <- trainControl(
      method = "cv",
      number = 10,
      classProbs = TRUE,
      summaryFunction = prSummary,  # caret calcule la précision, le rappel, la F
      savePredictions = "final"
    )

    # Afficher la configuration
    train_control
    ```

## 7. Classifieurs :

1.  Méthode des K plus proches voisins (KNN)

    Transformation des variables qulitatives en numeric en appliquant
    Codage binaire (dummy coding)

    ```{r}
    dummy_encoder <- dummyVars(" ~ .", data = train_predictors)
    X_train_dummy <- data.frame(predict(dummy_encoder, newdata = train_predictors))
    X_test_dummy  <- data.frame(predict(dummy_encoder, newdata = test_predictors))
    X_val_dummy   <- data.frame(predict(dummy_encoder, newdata = val_predictors))


    str(X_train_dummy)
    str(X_test_dummy)
    str(X_val_dummy)

    ```

    -   Méthode des K plus proches voisins avec partage du jeu de
        données en Holdout

        Caretaker a appliqué un prétraitement de **centrage et
        réduction** sur 22 variables (les colonnes de `X_train_dummy`).

        À chaque pli, caretaker utilise environ 90 % du train (par ex.
        3600 observations) pour entraîner et le reste (400 obs. sur

        4000) pour valider, selon la répartition exacte.

        La légère variation (3600 vs 3601) vient du fait que caretaker
        fait une partition stratifiée (pour garder la proportion de
        classes).

        caretaker a testé plusieurs valeurs de k (5, 7, 9, 13, 15, 17,
        19, 21, 23).

        caretaker a constaté que k = 21 donne la **plus grande
        F-mesure** moyenne.

        On applique KNN sur training dataset et on calcule la matrice de
        confusion :

        **Le modèle** a environ 65 % d’accuracy, principalement en
        prédisant “rejeté” (sensible à la classe majoritaire).

        **La spécificité** est très faible (≈ 16 %), donc le modèle rate
        la plupart des “approuvés”.

        =\>Le modèle **“rate”** beaucoup de “approuvés”, ce qui peut
        être problématique dans un contexte d’octroi de crédit (vous
        voudriez bien repérer les “bons” clients).

        **L’AUC \~ 0.50** indique que, du point de vue “approuvé” vs
        “rejeté” (avec “rejeté” en classe positive et la proba de
        “approuvé”), la discrimination est quasi nulle.

        **Pour avoir un AUC plus élevé** (et plus cohérent), considérez
        “approuvé” comme la classe positive dans `roc()`, ou recodez
        l’ordre du facteur.

        =\>En clair, le modèle **favorise la classe “rejeté”** (ce qui
        est cohérent si “rejeté” est majoritaire), obtenant une
        sensibilité correcte pour “rejeté” mais une très faible
        spécificité pour “approuvé”

        **Apres changement de metriques :**

        -   accuracy = 0.898. Le modèle est correct \~89,8 % du temps.

        -   sensiblity = 0.95 . 95,85 % des vrais “rejetés” sont bien
            classés “rejeté”.

        -   specificity = 0.693 . 69,3 % des vrais “approuvés” sont bien
            prédits “approuvé”.

        -   auc elevee 0.935. Cela signifie que le modèle a une
            **excellente capacité de discrimination** globale pour
            séparer “rejeté” et “approuvé” d’après la probabilité
            associée à “approuvé”.

            =\> Le modèle est donc **fort** pour reconnaître les
            “rejetés” (classe majoritaire) et **raisonnablement bon**
            pour repérer les “approuvés”.

    ```{r}
    ########Sélection de l’hyperparamètre k (validation croisée interne)
    library(MLmetrics)
    library(Metrics)  
    set.seed(1234)
    #knn_model <- train(
    #  x = X_train_dummy,
    #  y = y_train,
    #  method = "knn",
    #  trControl = train_control,
    #  metric = "ROC",                  # Optimiser l'AUC
    #  preProcess = c("center", "scale"),  # Normalisation (centrage, réduction)
    #  tuneLength = 10                  # Tester 10 valeurs de k
    #)
    knn_model <- train(
      x = X_train_dummy,
      y = y_train,
      method = "knn",
      trControl = train_control,
      metric = "F",                    # On optimise la F-mesure
      preProcess = c("center", "scale"),
      tuneLength = 10
    )

    print(knn_model)
    plot(knn_model)
    cat("Meilleur k trouvé en CV =", knn_model$bestTune$k, "\n")

    ####### Une fois le meilleur k trouvé, caretaker réentraîne le modèle final sur tout le jeu d’entraînement (80%) avec ce k.

    pred_test <- predict(knn_model, newdata = X_test_dummy) #Applique le modèle k-NN (entraîné précédemment) aux données de test X_test_dummy.et retourne la classe prédite (“rejeté” ou “approuvé”) pour chaque observation du test.
    conf_matrix_test <- confusionMatrix(pred_test, y_test)
    print(conf_matrix_test)

    # Calcul de l'AUC pour train 
    library(pROC)
    prob_test <- predict(knn_model, newdata = X_test_dummy, type = "prob")
    roc_obj_test <- roc(
      response  = y_test,
      predictor = prob_test[,"approuvé"], 
      levels    = c("rejeté", "approuvé"),  # "approuvé" sera la classe positive
      direction = "<"                       # ou ">", à tester
    )
    cat("AUC sur le jeu de test =", auc(roc_obj_test), "\n")


    ######## sur validation
    pred_val <- predict(knn_model, newdata = X_val_dummy)
    conf_matrix_val <- confusionMatrix(pred_val, y_val)
    print(conf_matrix_val)

    prob_val <- predict(knn_model, newdata = X_val_dummy, type = "prob")
    roc_obj_val <- roc(
      response = y_val,
      predictor = prob_val[,"approuvé"],
      levels = c("rejeté", "approuvé"),
      direction = "<"
    )
    cat("AUC sur le validation set =", auc(roc_obj_val), "\n")
    ```

    -   Méthode des K plus proches voisins avec cross-validation pour
        sélectionner le nombre de voisins

    ```{r}
    library(caret)
    library(MLmetrics)   # Pour prSummary qui calcule Precision, Recall et F-mesure
    library(pROC)

    set.seed(123)  # Pour la reproductibilité

    # Configuration de la validation croisée sur tout le dataset (10-fold CV)
    train_control_cv <- trainControl(
      method = "cv",
      number = 10,
      classProbs = TRUE,            # Nécessaire pour obtenir les probabilités de classe
      summaryFunction = prSummary,  # Calcule Precision, Recall et F-mesure
      savePredictions = "final"
    )

    dummy_encoder_full <- dummyVars(" ~ .", data = predictive_vars)

    # 2) Application de l'encodeur à l'ensemble des données
    predictive_vars_dummy <- data.frame(
      predict(dummy_encoder_full, newdata = predictive_vars)
    )

    # 3) Vérification de la structure
    str(predictive_vars_dummy)

    # Entraînement du modèle k-NN en optimisant la F-mesure sur tout le dataset
    knn_cv_model <- train(
      x = predictive_vars_dummy,    # Utilise toutes les observations (sans holdout)
      y = target,                   # Variable cible
      method = "knn",
      trControl = train_control_cv,
      metric = "F",                 # Optimisation basée sur la F-mesure
      preProcess = c("center", "scale"),  # Normalisation
      tuneLength = 10               # Tester 10 valeurs différentes pour k
    )

    # Affichage des résultats et du tuning
    print(knn_cv_model)
    plot(knn_cv_model)
    cat("Meilleur k (CV sur tout le dataset) =", knn_cv_model$bestTune$k, "\n")

    ```

    -   Performance et conclusion

2.  Classifieur bayésien naïf

    -   Classifieur naïf bayésien avec partage du jeu de données en
        Holdout

        -Partage du jeu de données

    ```{r}
      trainIndex <- createDataPartition(predictive_vars$loan_status, p = 0.8, list = FALSE)
        trainData  <- predictive_vars[trainIndex, ]
        tempData   <- predictive_vars[-trainIndex, ]
    nobs    = nrow(qualitative_vars)
    inTrain = sample(1:nobs, size=round(0.8*nobs),replace=FALSE)
    target_train= target[trainIndex]
    ```

    -Phase d'apprentissage

    ```{r}
    install.packages("naivebayes")
     nobs    = nrow(qualitative_vars)
    inTrain = sample(1:nobs, size=round(0.8*nobs),replace=FALSE)
    predictive_vars_test1    = predictive_vars[-inTrain,]

    target_test1             = target[-inTrain]
    predictive_vars_train1   = predictive_vars[inTrain,]
    target_train1            = target[inTrain]
    predictive_vars_train1

        
    target_train= target[trainIndex]
    predictive_vars
    predictive_vars_test1

    library(naivebayes)
    ?naive_bayes

    trainData$loan_status <- as.factor(trainData$loan_status)
    inTrain$loan_status=as.factor(inTrain$loan_status)

    classif <- naive_bayes(x = trainData[, -which(names(trainData) == "loan_status")], 
                           y = trainData$loan_status)

    classif = naive_bayes(x = trainData, y = target_train)
    trainData
    predictive_vars_test1
    classif1= naive_bayes(x =predictive_vars_train1, y= target_train1,laplace=1)
    predictive_vars_train
    classif
    classif1
    ```

    ```{r, out.width="50%", fig.align = "center", eval = FALSE}
    plot(classif, prob = "conditional")
    ```

    -Prédiction sur le jeu de données de test des probabilités
    d'appartenir aux différentes catégories de la réponse

    ```{r}
    pred = predict(classif, testData, type = "prob")
    pred
    ```

    -Prédiction de la target sur le jeu de données de test

    ```{r}
    # Prédiction de la target sur le jeu de test

    target_pred1 = predict(classif,predictive_vars_test1, type = "class")

    target_pred1

    mean(target_pred1 == target_test1)
    recall(data = target_pred1, reference = target_test1, relevant = "approuvé")
    precision(data = target_pred1,  reference = target_test1, relevant = "approuvé")

    # Tracer le boxplot des probabilités prédites en fonction du genre
    pred <- predict(classif, newdata = testData, type = "prob")

    boxplot(pred[, 2] ~ testData$previous_loan_defaults_on_file, 
            col = c("pink", "lightblue"), 
            main = "Probabilité prédite de loan_status en fonction du previous_loan_defaults_on_file", 
            ylab = "Probabilité prédite de loan_status", 
            xlab = "Genre de la personne")

    ```

    -Classifieur naïf bayésien avec 10-fold cross-validation pour
    évaluer le classifieur

    ```{r}
    set.seed(1357)
    nfolds      = 10

    folds = NULL
    for(i in 1:nobs){
      folds = c(folds,sample(1:nfolds,1,replace=FALSE))
    }



    accuracy_fold   = NULL
    recall_fold     = NULL
    precision_fold  = NULL

    for(fold in 1:nfolds){ # pour faire les itérations de la CV
      inFold                  = which(folds == fold)
      
      predictive_vars_test2    = predictive_vars[inFold,] # pour évaluer le modèle
      target_test2             = target[inFold]
      predictive_vars_train2   = predictive_vars[-inFold,] # pour entrainer le modèle
      target_train2            = target[-inFold]
      
     
      classif2 = naive_bayes(x = predictive_vars_train2, y = target_train2,laplace=1)
      target_pred2 = predict(classif2, predictive_vars_test2, type = "class") #voir 2.5
      
      accuracy_test = mean(target_pred2 == target_test2)
      recall_test= recall(data = target_pred2, reference = target_test2, relevant = "approuvé")
    precision_test = precision(data = target_pred2,  reference = target_test2, relevant = "approuvé")
     
      accuracy_fold = rbind(accuracy_fold, accuracy_test)
      recall_fold = rbind(recall_fold, recall_test)
      precision_fold = rbind(precision_fold, precision_test)
    }
    rownames(accuracy_fold) = paste0("fold_",1:nfolds)
    rownames(recall_fold) = paste0("fold_",1:nfolds)
    rownames(precision_fold) = paste0("fold_",1:nfolds)

    ```

    -Performance et conclusion

3.  Abre de classification

    -   Variables explicatives utilisée pour la prédiction

        1.  1 Arbre de classification avec évaluation des performances
            en Holdout

            -   Partage du jeu de données

            -   Gestion des données manquantes

            -   Phase d'apprentissage

            -   Prédiction de la target avec l'arbre de décision sur le
                jeu de données de test

            -   Élagage de l'arbre

            -   Prédiction de la target avec l'arbre élagué sur le jeu
                de données de test

        2.  1 Arbre de classification avec évaluation des performances
            en 10-fold cross-validation

            -   Sans élagage

            -   Avec élagage

## 8. Métriques d'évaluation :

1.  Accuracy, recall, precision, F1score

2.  AUC

3.  Évaluation du classifieur

## 9. Data leakage :

Conclusion

Parmi les classifieurs que nous avons étudiés (k-NN, Naive Bayes et
Arbres de décision), l’arbre de décision (via l’algorithme CART) se
démarque comme le meilleur choix pour notre problème de prédiction de
l’approbation de prêt. Voici pourquoi :

• Les arbres de décision gèrent naturellement à la fois les variables
numériques et catégorielles sans nécessiter de normalisation préalable.
Ils permettent de capturer des interactions non linéaires entre les
variables, ce qui est crucial dans le domaine du crédit où les relations
entre l’âge, l’expérience professionnelle et le comportement de crédit
peuvent être complexes.

• Ils offrent une excellente interprétabilité. Dans un contexte
financier, comprendre pourquoi un prêt a été approuvé ou rejeté est
essentiel pour justifier les décisions et pour respecter les exigences
réglementaires.

• Bien que le k-NN et le Naive Bayes soient intéressants, le k-NN est
très sensible à la mise à l’échelle et aux outliers, et le Naive Bayes
repose sur l’hypothèse forte d’indépendance conditionnelle entre les
variables, ce qui est rarement le cas en pratique pour des données de
crédit.

Pour ce qui est des métriques d’évaluation, l’AUC-ROC est la plus
appropriée dans notre cas car elle mesure la capacité discriminante du
modèle sans être biaisée par le déséquilibre des classes (ici, un nombre
nettement plus élevé de demandes rejetées). Le F1-score est également
utile car il combine précision et rappel, ce qui est important lorsque
les coûts associés aux fausses approbations (ou aux fausses rejets) sont
élevés.

En résumé, pour notre jeu de données, un arbre de décision (ou
idéalement une approche par forêts aléatoires, qui étend cette méthode
pour gagner en robustesse) couplé à l’AUC-ROC et au F1-score pour
l’évaluation est un choix judicieux et pragmatique.

### Brouillon :

```{r}
######categorisation age

#max(data$person_age)
#min(data$person_age)
# Calcul des quantiles à 0%, 50% et 100%
#q = quantile(data$person_age, probs = c(0, 0.5, 1), na.rm = TRUE)
# q renverra c(valeur_min, mediane, valeur_max)

# Découpage
#data$person_age <- cut(
#  data$person_age,
#  breaks = q,
#  include.lowest = TRUE,
#  labels = c("plus jeune", "plus adulte")
#)
#data$person_age = as.factor(data$person_age)
# summary(data$person_age)


#####label encoding de home_ownership

#levels = c("RENT", "OWN", "MORTGAGE", "OTHER")

#data$person_home_ownership = factor(
#  data$person_home_ownership,
# levels = levels
#)

#data$person_home_ownership_num = as.integer(data$person_home_ownership) - 1

















#####Brouillon car ca marche pas pour moi
#credit_score
#data$credit_score = cut(
#    data$credit_score,
 #   breaks = c(300, 580, 670, 740, 800, 851),  # 851 permet d'inclure 850 dans le dernier intervalle
 #   labels = c("faible", "moyen/limite", "bon", "très bon", "excellent"),
 #   include.lowest = TRUE,
 #   right = FALSE  # intervalles fermés à gauche et ouverts à droite : [300,580), [580,670), etc.
 # )
#data$credit_score = as.factor(data$credit_score)
#class(data$credit_score)
#summary(data$credit_score)

#previous loan defaults file 
#data$previous_loan_defaults_on_file=1*(data$previous_loan_defaults_on_file == "Yes")


#en factor
#data$credit_score = as.factor(data$credit_score)
#class(data$credit_score)

#transformation de data$person_home_ownership en factor
#data$person_home_ownership = as.factor(data$person_home_ownership)
#class(data$person_home_ownership)

#transformation de data$loan_intent en factor
#data$loan_intent = as.factor(data$loan_intent)
#class(data$loan_intent)

#transformation de credit_score en factor
#data$previous_loan_defaults_on_file = as.factor(data$previous_loan_defaults_on_file)
#class(data$previous_loan_defaults_on_file)


#contenant les variables qualitatives que l'on souhaite utiliser pour la prédiction
#qualitative_vars = data.frame(credit_score=data$credit_score, person_home_ownership= data$person_home_ownership, loan_intent=data$loan_intent, previous_loan_defaults_on_file=data$previous_loan_defaults_on_file)

##contenant les variables quantitatives que l'on souhaite utiliser pour la prédiction
#quantitative_vars = data.frame(person_age= data$person_age, person_emp_exp=data$person_emp_exp, loan_percent_income=data$loan_percent_income, loan_int_rate=data$loan_int_rate , cb_person_cred_hist_length=data$cb_person_cred_hist_length)


#summary(quantitative_vars)
#summary(qualitative_vars)
#summary(target)




```
